from fastapi import FastAPI, HTTPException, Depends, Query, BackgroundTasks, UploadFile, File, Path
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy import func, text, distinct
from sqlalchemy.orm import Session
from typing import Optional, List, Dict, Any, Union, Tuple
from datetime import datetime
import os
import sys
import logging
import shutil
from pathlib import Path
import pandas as pd
from pydantic import BaseModel
import re


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from database import engine, SessionLocal, get_db

def parse_time(time_str: str) -> Optional[datetime]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É 'HH:MM:SS' –≤ datetime.time, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"""
    try:
        if not time_str or time_str.upper() == "ZZ:ZZ:00":
            return None
        return datetime.strptime(time_str, "%H:%M:%S")
    except Exception:
        return None

def parse_coord(coord_str: str) -> Tuple[Optional[float], Optional[float]]:
    """–ü–∞—Ä—Å–∏—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
    if not coord_str:
        return None, None
    match = re.match(r"(\d{2,3})(\d{2})([NS])(\d{3})(\d{2})([EW])", coord_str.strip())
    if not match:
        return None, None

    lat_deg = int(match.group(1))
    lat_min = int(match.group(2))
    lat_sign = 1 if match.group(3) == "N" else -1
    lat = lat_sign * (lat_deg + lat_min / 60.0)

    lon_deg = int(match.group(4))
    lon_min = int(match.group(5))
    lon_sign = 1 if match.group(6) == "E" else -1
    lon = lon_sign * (lon_deg + lon_min / 60.0)

    return round(lat, 6), round(lon, 6)

def convert_coord(coord: str) -> Dict[str, Optional[float]]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ '5957N02905E' –≤ {latitude, longitude}
    """
    try:
        # –†–∞–∑–±–∏—Ä–∞–µ–º —à–∏—Ä–æ—Ç—É
        lat_deg = int(coord[0:2])
        lat_min = int(coord[2:4])
        lat_dir = coord[4].upper()
        latitude = lat_deg + lat_min / 60
        if lat_dir == 'S':
            latitude = -latitude

        # –†–∞–∑–±–∏—Ä–∞–µ–º –¥–æ–ª–≥–æ—Ç—É
        lon_deg = int(coord[5:8])
        lon_min = int(coord[8:10])
        lon_dir = coord[10].upper()
        longitude = lon_deg + lon_min / 60
        if lon_dir == 'W':
            longitude = -longitude

        return {"latitude": latitude, "longitude": longitude}
    except Exception:
        return {"latitude": None, "longitude": None}

def parse_flight_duration(dep: str, arr: str) -> Optional[float]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –ø—Ä–∏–±—ã—Ç–∏—è –≤ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º–∏–Ω—É—Ç–∞—Ö.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ.
    """
    try:
        dep_time = datetime.strptime(dep, "%H:%M:%S")
        arr_time = datetime.strptime(arr, "%H:%M:%S")
        duration = (arr_time - dep_time).total_seconds() / 60
        # –ï—Å–ª–∏ —Ä–µ–π—Å –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç –ø–æ–ª–Ω–æ—á—å, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º
        if duration < 0:
            duration += 24 * 60
        return duration
    except Exception:
        return None
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ —Å –∏–º–µ–Ω–µ–º —Ü–µ–ª–µ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
TARGET_TABLE = "excel_data_result_1"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

# –ú–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
class RegionCreate(BaseModel):
    name: str
    description: Optional[str] = None

class FileUploadResponse(BaseModel):
    status: str
    message: str
    filename: str
    file_path: str
    records_processed: Optional[int] = None

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(title="–ë–í–° API", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def clean_column_name(col):
    """–û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫"""
    if pd.isna(col):
        return "unknown"
    col = str(col)
    # –ó–∞–º–µ–Ω—è–µ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—É –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü—É
    cyrillic_to_latin = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'YO',
        '–ñ': 'ZH', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
        '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
        '–§': 'F', '–•': 'H', '–¶': 'TS', '–ß': 'CH', '–®': 'SH', '–©': 'SCH',
        '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'YU', '–Ø': 'YA'
    }
    
    for cyr, lat in cyrillic_to_latin.items():
        col = col.replace(cyr, lat)
    
    col = col.lower()
    col = re.sub(r'[\s\-\.\/\\]+', '_', col)
    col = re.sub(r'[^a-z0-9_]', '', col)
    col = re.sub(r'_+', '_', col)
    col = col.strip('_')
    
    if not col or col[0].isdigit():
        col = f'col_{hash(col) % 10000}'
    
    return col


def process_uploaded_excel_simple(file_path: str, db: Session):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ Excel —Ñ–∞–π–ª–∞"""
    try:
        logger.info(f"üîÑ –ù–∞—á–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º processor
        from excel_processor import process_excel_with_external_parser
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
        success = process_excel_with_external_parser(file_path)
        
        if success:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            record_count = db.execute(text("SELECT COUNT(*) FROM excel_data_result_1")).scalar()
            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {record_count}")
            return record_count or 0
        else:
            logger.error("‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π")
            return 0
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Excel: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return 0
    
def _find_column_case_insensitive(db: Session, table_name: str, target_columns: List[str]) -> Optional[str]:
    """–ù–∞—Ö–æ–¥–∏—Ç –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ —Å —É—á—ë—Ç–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞."""
    try:
        result = db.execute(text("""
            SELECT column_name
            FROM information_schema.columns
            WHERE table_name = :table_name
            AND table_schema = 'public'
        """), {"table_name": table_name})

        existing_columns = [row[0] for row in result.fetchall()]
        target_columns_lower = [col.lower() for col in target_columns]

        for existing_col in existing_columns:
            if existing_col.lower() in target_columns_lower:
                return existing_col
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∫–æ–ª–æ–Ω–∫–∏: {e}")
        return None

def _execute_safe_query(db: Session, query: str, params: Optional[Dict] = None) -> Any:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç SQL-–∑–∞–ø—Ä–æ—Å —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫."""
    try:
        logger.debug(f"–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å: {query}")
        result = db.execute(text(query), params or {})
        return result
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ '{query}': {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

def _get_required_columns(db: Session) -> Dict[str, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∏–º–µ–Ω–∞–º–∏ —Ç—Ä–µ–±—É–µ–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ —Å fallback –ª–æ–≥–∏–∫–æ–π"""
    columns_mapping = {
        "reg": ["reg", "REG", "registration", "—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è", "–±–æ—Ä—Ç", "–±–æ—Ä—Ç–æ–≤–æ–π –Ω–æ–º–µ—Ä"],
        "opr": ["opr", "OPR", "operator", "–æ–ø–µ—Ä–∞—Ç–æ—Ä", "–∞–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è", "—ç–∫—Å–ø–ª—É–∞—Ç–∞–Ω—Ç"],
        "typ": ["typ", "TYP", "type", "—Ç–∏–ø", "—Ç–∏–ø –≤—Å—É", "–≤–æ–∑–¥—É—à–Ω–æ–µ —Å—É–¥–Ω–æ"],
        "dep": ["dep", "DEP", "departure", "–≤—ã–ª–µ—Ç", "–∞—ç—Ä–æ–ø–æ—Ä—Ç –≤—ã–ª–µ—Ç–∞", "–æ—Ç–∫—É–¥–∞"],
        "dest": ["dest", "DEST", "destination", "–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ", "–∞—ç—Ä–æ–ø–æ—Ä—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è", "–∫—É–¥–∞"],
        "flight_zone_radius": ["flight_zone_radius", "FLIGHT_ZONE_RADIUS", "radius", "—Ä–∞–¥–∏—É—Å", "–∑–æ–Ω–∞ –ø–æ–ª–µ—Ç–∞"],
        "flight_level": ["flight_level", "FLIGHT_LEVEL", "level", "—É—Ä–æ–≤–µ–Ω—å", "—ç—à–µ–ª–æ–Ω"],
        "departure_time": ["departure_time", "DEPARTURE_TIME", "departure", "–≤—Ä–µ–º—è_–≤—ã–ª–µ—Ç–∞", "dep", "–≤—ã–ª–µ—Ç", "–≤—Ä–µ–º—è –≤—ã–ª–µ—Ç–∞"],
        "arrival_time": ["arrival_time", "ARRIVAL_TIME", "arrival", "–≤—Ä–µ–º—è_–ø—Ä–∏–±—ã—Ç–∏—è", "arr", "–ø—Ä–∏–±—ã—Ç–∏–µ", "–≤—Ä–µ–º—è –ø—Ä–∏–±—ã—Ç–∏—è"],
        "tsentr_es_orvd": ["tsentr_es_orvd", "TSENTR_ES_ORVD", "—Ü–µ–Ω—Ç—Ä", "center", "—Ä–µ–≥–∏–æ–Ω", "–æ—Ä–≤–¥"]
    }

    result = {}
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ
    try:
        existing_columns_result = db.execute(text(f"""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = '{TARGET_TABLE}' 
            AND table_schema = 'public'
        """))
        existing_columns = [row[0] for row in existing_columns_result.fetchall()]
        
        logger.info(f"–ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ: {existing_columns}")
        
        # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π —Ç—Ä–µ–±—É–µ–º–æ–π –∫–æ–ª–æ–Ω–∫–∏
        for key, variants in columns_mapping.items():
            column_found = None
            for variant in variants:
                # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
                for existing_col in existing_columns:
                    if existing_col.lower() == variant.lower():
                        column_found = existing_col
                        break
                if column_found:
                    break
            
            if column_found:
                result[key] = column_found
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è '{key}': {column_found}")
            else:
                logger.warning(f"‚ùå –ö–æ–ª–æ–Ω–∫–∞ '{key}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ —Å—Ä–µ–¥–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {variants}")
                
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–ª–æ–Ω–æ–∫ —Ç–∞–±–ª–∏—Ü—ã: {e}")
    
    return result

@app.on_event("startup")
async def startup_event():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ FastAPI"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ë–í–° API...")
    db = SessionLocal()
    try:
        table_exists = db.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name = :table_name
            )
        """), {"table_name": TARGET_TABLE}).scalar()

        if table_exists:
            record_count = db.execute(text(f"SELECT COUNT(*) FROM {TARGET_TABLE}")).scalar()
            logger.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ {TARGET_TABLE} –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø–∏—Å–µ–π: {record_count}")

            columns_result = db.execute(text("""
                SELECT column_name, data_type
                FROM information_schema.columns
                WHERE table_name = :table_name
                ORDER BY ordinal_position
            """), {"table_name": TARGET_TABLE})

            columns = [f"{row[0]} ({row[1]})" for row in columns_result]
            logger.info(f"üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã: {columns}")
        else:
            logger.info(f"‚ÑπÔ∏è –¢–∞–±–ª–∏—Ü–∞ {TARGET_TABLE} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª —á–µ—Ä–µ–∑ /api/upload-excel")
    except Exception as e:
        logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {e}")
    finally:
        db.close()

# –≠–ù–î–ü–û–ò–ù–¢ –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò –§–ê–ô–õ–û–í
@app.post("/api/upload-excel", response_model=FileUploadResponse)
async def upload_excel_file(
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ Excel —Ñ–∞–π–ª–æ–≤"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if file.filename and not file.filename.lower().endswith(('.xlsx', '.xls')):
            raise HTTPException(
                status_code=400, 
                detail="–†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã Excel (.xlsx, .xls)"
            )

        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        UPLOAD_DIR.mkdir(exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª —Å –∞–±—Å–æ–ª—é—Ç–Ω—ã–º –ø—É—Ç–µ–º
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_filename = file.filename or f"unknown_{timestamp}.xlsx"
        file_path = UPLOAD_DIR / f"uploaded_{timestamp}_{safe_filename}"
        
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤: {file_path.absolute()}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è
        if not file_path.exists():
            raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª")
            
        file_size = file_path.stat().st_size
        logger.info(f"üìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path} ({file_size} bytes)")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å –ê–ë–°–û–õ–Æ–¢–ù–´–ú –ø—É—Ç–µ–º
        absolute_file_path = str(file_path.absolute())
        records_processed = process_uploaded_excel_simple(absolute_file_path, db)

        return FileUploadResponse(
            status="success",
            message=f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –ó–∞–ø–∏—Å–µ–π: {records_processed}",
            filename=safe_filename,
            file_path=absolute_file_path,
            records_processed=records_processed
        )

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")

@app.get("/api/table-structure")
async def get_table_structure(db: Session = Depends(get_db)):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    try:
        result = db.execute(text(f"""
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns 
            WHERE table_name = '{TARGET_TABLE}' 
            AND table_schema = 'public'
            ORDER BY ordinal_position
        """))
        
        columns = []
        for row in result:
            columns.append({
                "name": row[0],
                "type": row[1],
                "nullable": row[2]
            })
        
        # –¢–∞–∫–∂–µ –ø–æ–ª—É—á–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        sample_data = db.execute(text(f"SELECT * FROM {TARGET_TABLE} LIMIT 5")).fetchall()
        sample_columns = db.execute(text(f"SELECT * FROM {TARGET_TABLE} LIMIT 1")).keys()
        
        sample_records = []
        for row in sample_data:
            sample_records.append(dict(zip(sample_columns, row)))
        
        return {
            "table_name": TARGET_TABLE,
            "columns": columns,
            "sample_data": sample_records,
            "total_columns": len(columns)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞: {str(e)}")

# –û–°–ù–û–í–ù–´–ï –≠–ù–î–ü–û–ò–ù–¢–´
@app.get("/")
async def get_main_data(db: Session = Depends(get_db)):
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –ø–æ–ª—è–º–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        columns = _get_required_columns(db)
        
        # –ï—Å–ª–∏ –Ω–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ
        available_columns = {k: v for k, v in columns.items() if v}
        
        if not available_columns:
            # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ —á—Ç–æ –µ—Å—Ç—å
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ")
            result = _execute_safe_query(db, f"SELECT * FROM {TARGET_TABLE} LIMIT 100")
            data = [dict(row) for row in result.mappings().all()]
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫
            all_columns_result = db.execute(text(f"""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = '{TARGET_TABLE}' 
                ORDER BY ordinal_position
            """))
            all_columns = [row[0] for row in all_columns_result.fetchall()]
            
            return {
                "data": data,
                "count": len(data),
                "columns": all_columns,
                "warning": "–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã)"
            }

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        select_columns = []
        for key, column_name in available_columns.items():
            select_columns.append(f'"{column_name}" as {key}')

        query = f"SELECT {', '.join(select_columns)} FROM {TARGET_TABLE}"
        result = _execute_safe_query(db, query)

        data = [dict(row) for row in result.mappings().all()]

        return {
            "data": data,
            "count": len(data),
            "columns": list(available_columns.keys()),
            "available_columns": available_columns
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞: {str(e)}")
    
@app.get("/statistics")
async def get_statistics(
    limit: Optional[int] = Query(None, description="–õ–∏–º–∏—Ç –∑–∞–ø–∏—Å–µ–π"),
    offset: int = Query(0, description="–°–º–µ—â–µ–Ω–∏–µ"),
    db: Session = Depends(get_db)
):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        table_exists = db.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name = :table_name
            )
        """), {"table_name": TARGET_TABLE}).scalar()

        if not table_exists:
            raise HTTPException(status_code=404, detail=f"–¢–∞–±–ª–∏—Ü–∞ {TARGET_TABLE} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        total_count_result = db.execute(text(f"SELECT COUNT(*) FROM {TARGET_TABLE}"))
        total_count = total_count_result.scalar() or 0

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if limit is None:
            result = db.execute(text(f"SELECT * FROM {TARGET_TABLE} OFFSET :offset"), {"offset": offset})
        else:
            result = db.execute(
                text(f"SELECT * FROM {TARGET_TABLE} LIMIT :limit OFFSET :offset"),
                {"limit": limit, "offset": offset}
            )

        columns = result.keys()
        data = [dict(zip(columns, row)) for row in result.fetchall()]

        has_more = False
        if limit is not None and total_count is not None:
            has_more = (offset + limit) < total_count

        return {
            "data": data,
            "pagination": {
                "limit": limit,
                "offset": offset,
                "total": total_count,
                "has_more": has_more
            }
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ /statistics: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞: {str(e)}")
    
@app.get("/city/{city_name}")
async def get_city_data(
    city_name: str,  # –£–±—Ä–∞–ª = Path(...)
    db: Session = Depends(get_db)
):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∞ –ï–° –û–†–í–î"""
    try:
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ü–µ–Ω—Ç—Ä–æ–º –ï–° –û–†–í–î
        center_column = _find_column_case_insensitive(db, TARGET_TABLE, [
            "tsentr_es_orvd", "TSENTR_ES_ORVD", "—Ü–µ–Ω—Ç—Ä", "center"
        ])

        if not center_column:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å —Ü–µ–Ω—Ç—Ä–æ–º –ï–° –û–†–í–î (tsentr_es_orvd)"
            )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —Å —Ç–æ—á–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
        query = f"""
            SELECT * FROM {TARGET_TABLE}
            WHERE "{center_column}" = :city_name
        """

        result = _execute_safe_query(db, query, {"city_name": city_name})

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        columns = result.keys()
        data = []
        for row in result.fetchall():
            row_dict = dict(zip(columns, row))
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º datetime –≤ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–∫–∏–µ –ø–æ–ª—è
            for key, value in row_dict.items():
                if isinstance(value, datetime):
                    row_dict[key] = value.isoformat()
            data.append(row_dict)

        return {
            "center": city_name,
            "data": data,
            "count": len(data),
            "column_used": center_column
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ /city/{city_name}: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞: {str(e)}")
# –≠–ù–î–ü–û–ò–ù–¢–´ –° –ü–ê–†–°–ò–ù–ì–û–ú –ö–û–û–†–î–ò–ù–ê–¢

@app.get("/stats/regions", response_model=List[Dict])
def get_stats_regions(db: Session = Depends(get_db)):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–π—Å–æ–≤ –∏ —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"""
    try:
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ü–µ–Ω—Ç—Ä–æ–º –ï–° –û–†–í–î
        center_column = _find_column_case_insensitive(db, TARGET_TABLE, [
            "tsentr_es_orvd", "TSENTR_ES_ORVD", "—Ü–µ–Ω—Ç—Ä", "center"
        ])
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
        time_columns = _get_required_columns(db)
        departure_time_col = time_columns.get("departure_time")
        arrival_time_col = time_columns.get("arrival_time")
        
        if not center_column:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å —Ü–µ–Ω—Ç—Ä–æ–º –ï–° –û–†–í–î"
            )

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏, —Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
        if departure_time_col and arrival_time_col:
            query = text(f"""
                SELECT {center_column}, {departure_time_col}, {arrival_time_col} 
                FROM {TARGET_TABLE} 
                WHERE {departure_time_col} IS NOT NULL AND {arrival_time_col} IS NOT NULL
            """)
            result = db.execute(query).mappings().all()

            stats = {}
            for row in result:
                region = row[center_column]
                dep_time = row[departure_time_col]
                arr_time = row[arrival_time_col]

                if not region:
                    continue

                # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –∏ –≤—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                dep = parse_time(str(dep_time)) if dep_time else None
                arr = parse_time(str(arr_time)) if arr_time else None
                
                duration = None
                if dep and arr:
                    duration = parse_flight_duration(
                        dep.strftime("%H:%M:%S") if hasattr(dep, 'strftime') else str(dep),
                        arr.strftime("%H:%M:%S") if hasattr(arr, 'strftime') else str(arr)
                    )

                if region not in stats:
                    stats[region] = {"num_flights": 0, "total_duration": 0, "flights_with_duration": 0}

                stats[region]["num_flights"] += 1
                if duration is not None:
                    stats[region]["total_duration"] += duration
                    stats[region]["flights_with_duration"] += 1

            result_list = []
            for region, data in stats.items():
                avg_duration = 0
                if data["flights_with_duration"] > 0:
                    avg_duration = data["total_duration"] / data["flights_with_duration"]
                
                result_list.append({
                    "region": region,
                    "num_flights": data["num_flights"],
                    "avg_flight_duration": round(avg_duration, 2),
                    "flights_with_duration_data": data["flights_with_duration"]
                })
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –≤—Ä–µ–º–µ–Ω–∏, —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–π—Å–æ–≤
            query = text(f"SELECT {center_column}, COUNT(*) as flight_count FROM {TARGET_TABLE} GROUP BY {center_column}")
            result = db.execute(query).mappings().all()

            result_list = []
            for row in result:
                region = row[center_column]
                if region:
                    result_list.append({
                        "region": region,
                        "num_flights": row["flight_count"],
                        "avg_flight_duration": 0,
                        "flights_with_duration_data": 0
                    })

        return result_list

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

@app.get("/stats/region/{region_name}")
def region_stats(region_name: str, db: Session = Depends(get_db)):
    """–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ä–µ–≥–∏–æ–Ω—É"""
    try:
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ü–µ–Ω—Ç—Ä–æ–º –ï–° –û–†–í–î
        center_column = _find_column_case_insensitive(db, TARGET_TABLE, [
            "tsentr_es_orvd", "TSENTR_ES_ORVD", "—Ü–µ–Ω—Ç—Ä", "center"
        ])
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
        time_columns = _get_required_columns(db)
        departure_time_col = time_columns.get("departure_time")
        arrival_time_col = time_columns.get("arrival_time")
        
        if not center_column:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å —Ü–µ–Ω—Ç—Ä–æ–º –ï–° –û–†–í–î"
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞
        region_exists = db.execute(text(f"""
            SELECT EXISTS (
                SELECT 1 FROM {TARGET_TABLE} WHERE {center_column} = :region
            )
        """), {"region": region_name}).scalar()

        if not region_exists:
            raise HTTPException(status_code=404, detail="–†–µ–≥–∏–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–π—Å–æ–≤
        total_query = text(f"""
            SELECT COUNT(*) as flight_count
            FROM {TARGET_TABLE}
            WHERE {center_column} = :region
        """)
        total_result = db.execute(total_query, {"region": region_name}).fetchone()
        total_flights = total_result[0] if total_result else 0

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏, –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        avg_duration = 0
        if departure_time_col and arrival_time_col:
            time_query = text(f"""
                SELECT {departure_time_col}, {arrival_time_col}
                FROM {TARGET_TABLE}
                WHERE {center_column} = :region 
                AND {departure_time_col} IS NOT NULL 
                AND {arrival_time_col} IS NOT NULL
            """)
            time_result = db.execute(time_query, {"region": region_name}).fetchall()

            durations = []
            for row in time_result:
                dep_time = row[0]
                arr_time = row[1]
                
                if dep_time and arr_time:
                    duration = parse_flight_duration(
                        str(dep_time), 
                        str(arr_time)
                    )
                    if duration is not None:
                        durations.append(duration)

            if durations:
                avg_duration = sum(durations) / len(durations)

        return {
            "region": region_name,
            "total_flights": total_flights,
            "average_duration_minutes": round(avg_duration, 2),
            "flights_with_duration_data": len(durations) if 'durations' in locals() else 0
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {region_name}: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

@app.get("/flights/points", response_model=List[Dict])
def get_flight_points(db: Session = Depends(get_db)):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ—á–µ–∫ –≤–∑–ª–µ—Ç–∞ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–π—Å–æ–≤: id + –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã"""
    try:
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –≤—ã–ª–µ—Ç–∞
        dep_column = _find_column_case_insensitive(db, TARGET_TABLE, [
            "dep_1", "DEP_1", "dep", "DEP", "departure_coords", "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã_–≤—ã–ª–µ—Ç–∞"
        ])
        
        if not dep_column:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –≤—ã–ª–µ—Ç–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
            return []

        query = text(f"SELECT id, {dep_column} FROM {TARGET_TABLE} WHERE {dep_column} IS NOT NULL")
        result = db.execute(query)
        points = []

        for row in result.fetchall():
            coord_str = str(row[1]) if row[1] else ""
            if coord_str:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º convert_coord –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                coords = convert_coord(coord_str)
                if coords["latitude"] is not None and coords["longitude"] is not None:
                    points.append({
                        "id": row[0],
                        "latitude": coords["latitude"],
                        "longitude": coords["longitude"],
                        "raw_coords": coord_str,
                        "parsed_method": "convert_coord"
                    })
                else:
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ parse_coord
                    lat, lon = parse_coord(coord_str)
                    if lat is not None and lon is not None:
                        points.append({
                            "id": row[0],
                            "latitude": lat,
                            "longitude": lon,
                            "raw_coords": coord_str,
                            "parsed_method": "parse_coord"
                        })
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ç–æ—á–µ–∫ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: {len(points)}")
        return points

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ—á–µ–∫ –ø–æ–ª–µ—Ç–æ–≤: {e}")
        return []

@app.get("/flights/{flight_id}")
def get_flight(flight_id: int, db: Session = Depends(get_db)):
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Ä–µ–π—Å–µ"""
    try:
        result = db.execute(text(f"SELECT * FROM {TARGET_TABLE} WHERE id = :fid"), {"fid": flight_id})
        row = result.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Flight not found")

        colnames = result.keys()
        record = dict(zip(colnames, row))

        # –ü–∞—Ä—Å–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤—ã–ª–µ—Ç–∞
        dep_coords_raw = record.get("dep_1") or record.get("dep")
        dep_lat, dep_lon = parse_coord(str(dep_coords_raw)) if dep_coords_raw else (None, None)

        # –ü–∞—Ä—Å–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
        dest_coords_raw = record.get("dest") or record.get("arr")
        arr_lat, arr_lon = parse_coord(str(dest_coords_raw)) if dest_coords_raw else (None, None)

        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –ø–æ–ª–µ—Ç–∞ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
        dep_time = record.get("dep")
        arr_time = record.get("arr")
        flight_duration = None
        if dep_time and arr_time:
            flight_duration = parse_flight_duration(str(dep_time), str(arr_time))

        return {
            "id": record["id"],
            "region": record.get("tsentr_es_orvd"),
            "departure": {
                "raw": dep_coords_raw,
                "lat": dep_lat,
                "lon": dep_lon,
                "time": record.get("dep"),
                "parsed_success": dep_lat is not None and dep_lon is not None
            },
            "arrival": {
                "raw": dest_coords_raw,
                "lat": arr_lat,
                "lon": arr_lon,
                "time": record.get("arr"),
                "parsed_success": arr_lat is not None and arr_lon is not None
            },
            "flight_duration_minutes": flight_duration,
            "type": record.get("shr"),
            "reg_number": record.get("tsentr_es_orvd"),
            "operator": "–ù–µ —É–∫–∞–∑–∞–Ω",
            "remarks": record.get("source_sheet"),
            "flight_level": "–ù–µ —É–∫–∞–∑–∞–Ω",
            "flight_zone": "–ù–µ —É–∫–∞–∑–∞–Ω", 
            "flight_zone_radius": "–ù–µ —É–∫–∞–∑–∞–Ω",
            "dof": "–ù–µ —É–∫–∞–∑–∞–Ω",
            "sts": "–ù–µ —É–∫–∞–∑–∞–Ω",
            "source_sheet": record.get("source_sheet")
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–π—Å–∞ {flight_id}: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–π—Å–∞: {e}")

@app.get("/flights/{flight_id}/detailed")
def get_flight_detailed(flight_id: int, db: Session = Depends(get_db)):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–π—Å–µ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    try:
        result = db.execute(text(f"SELECT * FROM {TARGET_TABLE} WHERE id = :fid"), {"fid": flight_id})
        row = result.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Flight not found")

        colnames = result.keys()
        record = dict(zip(colnames, row))

        # –ü–∞—Ä—Å–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        dep_coords_raw = record.get("dep_1") or record.get("dep")
        dest_coords_raw = record.get("dest") or record.get("arr")
        
        dep_lat, dep_lon = parse_coord(str(dep_coords_raw)) if dep_coords_raw else (None, None)
        arr_lat, arr_lon = parse_coord(str(dest_coords_raw)) if dest_coords_raw else (None, None)

        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –ø–æ–ª–µ—Ç–∞
        dep_time = record.get("dep")
        arr_time = record.get("arr")
        flight_duration = None
        if dep_time and arr_time:
            flight_duration = parse_flight_duration(str(dep_time), str(arr_time))

        return {
            "flight_info": {
                "id": record["id"],
                "registration": record.get("tsentr_es_orvd"),
                "operator": "–ù–µ —É–∫–∞–∑–∞–Ω",
                "type": record.get("shr"),
                "region": record.get("tsentr_es_orvd"),
                "source_sheet": record.get("source_sheet")
            },
            "departure": {
                "raw_coordinates": dep_coords_raw,
                "latitude": dep_lat,
                "longitude": dep_lon,
                "time": record.get("dep"),
                "parsed_success": dep_lat is not None and dep_lon is not None
            },
            "arrival": {
                "raw_coordinates": dest_coords_raw,
                "latitude": arr_lat,
                "longitude": arr_lon,
                "time": record.get("arr"),
                "parsed_success": arr_lat is not None and arr_lon is not None
            },
            "flight_characteristics": {
                "flight_level": "–ù–µ —É–∫–∞–∑–∞–Ω",
                "flight_zone": "–ù–µ —É–∫–∞–∑–∞–Ω",
                "flight_zone_radius": "–ù–µ —É–∫–∞–∑–∞–Ω",
                "duration_minutes": flight_duration
            },
            "additional_info": {
                "remarks": record.get("source_sheet"),
                "dof": "–ù–µ —É–∫–∞–∑–∞–Ω",
                "sts": "–ù–µ —É–∫–∞–∑–∞–Ω"
            }
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ–π—Å–µ {flight_id}: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–π—Å–∞: {e}")
# –ê–î–ú–ò–ù–°–ö–ò–ï –≠–ù–î–ü–û–ò–ù–¢–´
@app.post("/admin/regions")
async def add_region( 
    region: RegionCreate,
    db: Session = Depends(get_db)
):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ä–µ–≥–∏–æ–Ω"""
    try:
        regions_table = "regions"

        table_exists = db.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name = :table_name
            )
        """), {"table_name": regions_table}).scalar()

        if not table_exists:
            raise HTTPException(status_code=404, detail=f"–¢–∞–±–ª–∏—Ü–∞ {regions_table} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        insert_query = f"""
            INSERT INTO {regions_table} (name, description)
            VALUES (:name, :description)
            RETURNING id
        """

        result = db.execute(text(insert_query), {
            "name": region.name,
            "description": region.description
        })

        fetched = result.fetchone()
        if fetched is None:
            db.rollback()
            raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å ID –Ω–æ–≤–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞")

        new_region_id = fetched[0]
        db.commit()

        return {
            "status": "success",
            "region_id": new_region_id,
            "region_name": region.name,
            "message": "–†–µ–≥–∏–æ–Ω —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω"
        }
    except Exception as e:
        db.rollback()
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Ä–µ–≥–∏–æ–Ω–∞: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞: {str(e)}")

@app.get("/health")
async def health():
    return {"status": "OK", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)